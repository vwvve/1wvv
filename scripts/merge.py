# !/usr/bin/env python
# -*-coding:utf-8 -*-

"""
@Project ï¼š1wvv 
@File    ï¼šmerge.py
@Author  ï¼švenus
@Date    ï¼š2025/8/16 ä¸‹åˆ1:44:47
@Des     ï¼šmerge
"""

import json
from urllib.parse import quote

import requests
from packaging import version
import re
import os
from pprint import pprint

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../"))
headers = {
    "user-agent": "Forward/316 CFNetwork/3826.600.41 Darwin/24.6.0"
}


def is_url_accessible(url: str) -> bool:
    try:
        resp = requests.head(url, allow_redirects=True, timeout=10)
        return 200 <= resp.status_code < 400
    except requests.RequestException:
        return False


def check_url_final(url: str):
    """
    æ£€æµ‹ URL æœ€ç»ˆæ˜¯å¦å¯è®¿é—®ã€‚
    è‡ªåŠ¨è·Ÿéšè·³è½¬ï¼Œå¹¶è¿”å›æœ€ç»ˆçŠ¶æ€ç å’Œæœ€ç»ˆ URLã€‚

    è¿”å›:
        (is_accessible, final_url, status_code)
    """
    try:
        # è·Ÿéšé‡å®šå‘ç›´åˆ°æœ€ç»ˆé¡µé¢
        resp = requests.head(url, headers=headers, allow_redirects=True, timeout=10)

        # å¦‚æœæœåŠ¡å™¨ä¸æ”¯æŒ HEADï¼Œåˆ™å°è¯• GETï¼ˆåªè·å–å¤´éƒ¨ï¼Œé¿å…ä¸‹è½½å…¨éƒ¨å†…å®¹ï¼‰
        if resp.status_code == 405:
            resp = requests.get(url, headers=headers, allow_redirects=True, stream=True, timeout=10)
            resp.close()

        final_url = resp.url
        status_code = resp.status_code
        is_accessible = 200 <= status_code < 300

        return is_accessible, final_url, status_code

    except requests.RequestException:
        return False, None, None


def url_to_repo(raw_url: str) -> str:
    m = re.match(r"https://raw\.githubusercontent\.com/([^/]+)/([^/]+)/", raw_url)
    if m:
        user, repo = m.groups()
        return f"https://github.com/{user}/{repo}"
    return raw_url


def get_repo(repo_path: str):
    """
    å°†ä»“åº“è½¬æ¢ä¸ºjson
    :param repo_path: è·¯å¾„
    :return: jsonå¯¹è±¡
    """

    widgets_path = os.path.join(BASE_DIR, repo_path.split("/")[0] + "/widgets")

    if not os.path.exists(widgets_path):
        os.makedirs(widgets_path)

    with open(os.path.join(BASE_DIR, repo_path), "r", encoding="utf-8") as f:
        repo_json = json.load(f)

        all_widgets = []
        thanks = []

        for name, url in repo_json.items():
            print(f"æ­£åœ¨è·å–: {name} -> {url}")
            try:
                resp = requests.get(url, timeout=15, headers=headers)
                resp.raise_for_status()
                text = re.sub(r",\s*([]}])", r"\1", resp.text)
                data = json.loads(text)
                widgets = data.get("widgets", [])

                all_widgets.extend(widgets)

                repo_link = url_to_repo(url)

                thanks.append(f"- [{name}]({repo_link})")
                print(f"  âœ… å·²åŠ è½½ {len(widgets)} ä¸ª widgets")

                # åˆ›å»ºæ¯ä¸ªname å°†å½“å‰repoä¸‹çš„widgetä¸‹è½½ä¿å­˜åˆ°name/widgetsç›®å½•ä¸‹

            except Exception as e:
                print(f"  âš ï¸ æ— æ³•è¯»å– {name}: {e}")
    return all_widgets, thanks


def try_decode(text):
    """å°è¯•ç”¨ä¸åŒçš„ç¼–ç è§£ç å­—ç¬¦ä¸²"""
    try:
        return text.encode('latin1').decode('utf-8')
    except:
        return text


def normalize_version(v: str):
    if not v:
        return version.parse("0.0.0")
    v_clean = re.sub(r"^[vV]", "", v.strip())
    try:
        return version.parse(v_clean)
    except Exception:
        return version.parse("0.0.0")


def get_name_after_last_slash(url):
    """
    è·å– URL ä¸­æœ€åä¸€ä¸ª  "/"  åçš„åå­—.
    Args:
      url: URL å­—ç¬¦ä¸².
    Returns:
      æœ€åä¸€ä¸ª  "/"  åçš„åå­—.  å¦‚æœ URL ä¸­æ²¡æœ‰  "/" , åˆ™è¿”å›æ•´ä¸ª URL.
    """
    last_slash_index = url.rfind("/")
    if last_slash_index == -1:
        return url
    else:
        return url[last_slash_index + 1:]


def change_repo_to_myself(file_path, owner="vwvve", repo="1wvv", branch="main"):
    return f"https://raw.githubusercontent.com/{owner}/{repo}/refs/heads/{branch}/{quote(file_path)}"


def download_widgets_script(widgets: list, widgets_path: str):
    merged = {}
    if widgets is not None:
        for widget in widgets:

            wid = widget.get("id")
            url = widget.get("url")

            w_author = widget.get("author")
            w_title = widget.get("title")

            if not wid or not url or not w_author:
                continue

            w_author = try_decode(widget.get("author"))

            w_path = os.path.join(widgets_path, w_author)
            if not os.path.exists(w_path):
                os.makedirs(w_path)

            ok, final_url, code = check_url_final(url)

            js_name = get_name_after_last_slash(url)
            js_path = os.path.join(w_path, js_name)

            if not ok:
                print(f"  âš ï¸ widget è¢«ç§»é™¤: {widget.get('id', '')} (æœ€ç»ˆ URL: {final_url}, çŠ¶æ€ç : {code})")
                continue

            # å…¨éƒ¨é‡æ–°ç¼–ç ä¸‹
            widget["id"] = widget.get("title").replace("ğŸ”", "").strip()
            widget["title"] = try_decode(widget.get("title"))
            widget["description"] = try_decode(widget.get("description"))
            widget["author"] = w_author

            try:
                # download
                resp = requests.get(final_url, timeout=15, headers=headers)
                resp.raise_for_status()
                with open(js_path, "wb") as f:
                    f.write(resp.content)  # ä½¿ç”¨ resp.content è·å–äºŒè¿›åˆ¶å†…å®¹
                print(f"æ–‡ä»¶ '{js_name}' å·²æˆåŠŸä¸‹è½½å¹¶ä¿å­˜åˆ° '{js_path}'")
            except Exception as e:
                print(f"  âš ï¸ æ— æ³•ä¸‹è½½ {url}: {e}")

            # è¿™æ˜¯åŸå§‹URL
            # widget["url"] = final_url
            widget["url"] = change_repo_to_myself(f"repo/widgets/{w_author}/{js_name}")

            cur_ver = normalize_version(widget.get("version", "0.0.0"))

            if w_title not in merged:
                # ä¹‹å‰æ²¡æœ‰è¿™ä¸ª idï¼Œç›´æ¥æ”¾è¿›å»
                merged[wid] = widget

            else:
                # å·²æœ‰ç›¸åŒ idï¼Œæ¯”è¾ƒç‰ˆæœ¬å·
                old_ver = normalize_version(merged[wid].get("version", "0.0.0"))
                if cur_ver > old_ver:
                    merged[wid] = widget
    return merged


def main():
    repo_path = "repo/repo.json"
    all_widgets, thanks = get_repo(repo_path)
    widgets_path = os.path.join(BASE_DIR, repo_path.split("/")[0] + "/widgets")
    merged = download_widgets_script(widgets=all_widgets, widgets_path=widgets_path)

    result = {
        "title": "1Wvv's AllInOne Widgets",
        "description": "åˆå¹¶è‡ªFW Widgetsæº(50% off code: 1w5.5)",
        "icon": "https://avatars.githubusercontent.com/u/225779571",
        "widgets": list(merged.values())
    }

    output_file = os.path.join(BASE_DIR, "allInOne.fwd")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(result['widgets'])} ä¸ª widgetï¼Œå·²ç”Ÿæˆ {output_file}")

    readme_content = "# 1Wvv's AllInOne Widgets\n\n" \
                     "æœ¬ä»“åº“è‡ªåŠ¨åˆå¹¶å¤šä¸ª ForwardWidgets æºï¼Œæ–¹ä¾¿ç»Ÿä¸€ä½¿ç”¨ã€‚(50% off code: 1w5.5)\n\n" \
                     "è‡ªåŠ¨æ£€æµ‹é“¾æ¥æ˜¯å¦æœ‰æ•ˆ, æœ€ç»ˆç”Ÿæˆé›†åˆä¸åŒ…å«æ— æ•ˆæ¨¡å—\n\n" \
                     f"ğŸ‘‰ [allinone.fwd](https://github.com/vwvve/1wvv/blob/main/allInOne.fwd)\n\n" \
                     "## æ„Ÿè°¢ä»¥ä¸‹åŸå§‹ä»“åº“ä½œè€…\n" \
                     + "\n".join(thanks) + "\n"

    readme_file = os.path.join(BASE_DIR, "README.md")
    with open(readme_file, "w", encoding="utf-8") as f:
        f.write(readme_content)

    print("âœ… README.md å·²æ›´æ–°")


if __name__ == '__main__':
    main()
